┌ Error: JULIA_CUDA_USE_BINARYBUILDER is deprecated. Call `CUDA.jl.set_runtime_version!` to use a local toolkit.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:200
┌ Warning: CUDA runtime library `libcublasLt.so.12` was loaded from a system path, `/apps/cuda/12.6.2/lib64/libcublasLt.so.12`.
│ This may cause errors.
│ 
│ If you're running under a profiler, this situation is expected. Otherwise,
│ ensure that your library path environment variable (e.g., `PATH` on Windows
│ or `LD_LIBRARY_PATH` on Linux) does not include CUDA library paths.
│ 
│ In any other case, please file an issue.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:218
┌ Warning: CUDA runtime library `libnvJitLink.so.12` was loaded from a system path, `/apps/cuda/12.6.2/lib64/libnvJitLink.so.12`.
│ This may cause errors.
│ 
│ If you're running under a profiler, this situation is expected. Otherwise,
│ ensure that your library path environment variable (e.g., `PATH` on Windows
│ or `LD_LIBRARY_PATH` on Linux) does not include CUDA library paths.
│ 
│ In any other case, please file an issue.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:218
┌ Warning: CUDA runtime library `libcusparse.so.12` was loaded from a system path, `/apps/cuda/12.6.2/lib64/libcusparse.so.12`.
│ This may cause errors.
│ 
│ If you're running under a profiler, this situation is expected. Otherwise,
│ ensure that your library path environment variable (e.g., `PATH` on Windows
│ or `LD_LIBRARY_PATH` on Linux) does not include CUDA library paths.
│ 
│ In any other case, please file an issue.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:218
┌ Error: JULIA_CUDA_USE_BINARYBUILDER is deprecated. Call `CUDA.jl.set_runtime_version!` to use a local toolkit.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:200
┌ Warning: CUDA runtime library `libcublasLt.so.12` was loaded from a system path, `/apps/cuda/12.6.2/lib64/libcublasLt.so.12`.
│ This may cause errors.
│ 
│ If you're running under a profiler, this situation is expected. Otherwise,
│ ensure that your library path environment variable (e.g., `PATH` on Windows
│ or `LD_LIBRARY_PATH` on Linux) does not include CUDA library paths.
│ 
│ In any other case, please file an issue.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:218
┌ Warning: CUDA runtime library `libnvJitLink.so.12` was loaded from a system path, `/apps/cuda/12.6.2/lib64/libnvJitLink.so.12`.
│ This may cause errors.
│ 
│ If you're running under a profiler, this situation is expected. Otherwise,
│ ensure that your library path environment variable (e.g., `PATH` on Windows
│ or `LD_LIBRARY_PATH` on Linux) does not include CUDA library paths.
│ 
│ In any other case, please file an issue.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:218
┌ Warning: CUDA runtime library `libcusparse.so.12` was loaded from a system path, `/apps/cuda/12.6.2/lib64/libcusparse.so.12`.
│ This may cause errors.
│ 
│ If you're running under a profiler, this situation is expected. Otherwise,
│ ensure that your library path environment variable (e.g., `PATH` on Windows
│ or `LD_LIBRARY_PATH` on Linux) does not include CUDA library paths.
│ 
│ In any other case, please file an issue.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:218
┌ Error: JULIA_CUDA_USE_BINARYBUILDER is deprecated. Call `CUDA.jl.set_runtime_version!` to use a local toolkit.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:200
┌ Warning: CUDA runtime library `libcublasLt.so.12` was loaded from a system path, `/apps/cuda/12.6.2/lib64/libcublasLt.so.12`.
│ This may cause errors.
│ 
│ If you're running under a profiler, this situation is expected. Otherwise,
│ ensure that your library path environment variable (e.g., `PATH` on Windows
│ or `LD_LIBRARY_PATH` on Linux) does not include CUDA library paths.
│ 
│ In any other case, please file an issue.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:218
┌ Warning: CUDA runtime library `libnvJitLink.so.12` was loaded from a system path, `/apps/cuda/12.6.2/lib64/libnvJitLink.so.12`.
│ This may cause errors.
│ 
│ If you're running under a profiler, this situation is expected. Otherwise,
│ ensure that your library path environment variable (e.g., `PATH` on Windows
│ or `LD_LIBRARY_PATH` on Linux) does not include CUDA library paths.
│ 
│ In any other case, please file an issue.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:218
┌ Warning: CUDA runtime library `libcusparse.so.12` was loaded from a system path, `/apps/cuda/12.6.2/lib64/libcusparse.so.12`.
│ This may cause errors.
│ 
│ If you're running under a profiler, this situation is expected. Otherwise,
│ ensure that your library path environment variable (e.g., `PATH` on Windows
│ or `LD_LIBRARY_PATH` on Linux) does not include CUDA library paths.
│ 
│ In any other case, please file an issue.
└ @ CUDA /g/data/e14/txs156/.julia/packages/CUDA/ja0IX/src/initialization.jl:218
[LOG_CAT_BASESMUMA] Failed to create rcache for KNEM device
[LOG_CAT_BASESMUMA] Failed to create rcache for KNEM device
[LOG_CAT_BASESMUMA] Failed to create rcache for KNEM device
┌ Info: Using architecture: Distributed{GPU{CUDABackend}} across 3 = 1×3×1 ranks:
│ ├── local_rank: 0 of 0-2
│ ├── local_index: [1, 1, 1]
└ └── connectivity: north=1 south=2
┌ Info: Using architecture: Distributed{GPU{CUDABackend}} across 3 = 1×3×1 ranks:
│ ├── local_rank: 1 of 0-2
│ ├── local_index: [1, 2, 1]
└ └── connectivity: north=2 south=0
┌ Info: Using architecture: Distributed{GPU{CUDABackend}} across 3 = 1×3×1 ranks:
│ ├── local_rank: 2 of 0-2
│ ├── local_index: [1, 3, 1]
└ └── connectivity: north=0 south=1
[ Info: Defining grid
[ Info: Defining vertical z faces
[ Info: Defining tripolar grid
[ Info: Defining grid
[ Info: Defining grid
[ Info: Defining vertical z faces
[ Info: Defining vertical z faces
[ Info: Defining tripolar grid
[ Info: Defining tripolar grid
[ Info: Done defining tripolar grid
[ Info: Defining bottom bathymetry
[ Info: Done defining tripolar grid
[ Info: Defining bottom bathymetry
[ Info: Done defining tripolar grid
[ Info: Defining bottom bathymetry
[ Info: Interpolation passes of bathymetry size (21600, 10800, 1) onto a TripolarGrid target grid of size (108, 54, 40):
[ Info:     pass 1 to size (108, 54, 1)
[ Info: Defining grid
[ Info: Defining grid
[ Info: Defining grid
[ Info: Defining closures
[ Info: Defining free surface
[ Info: Defining closures
[ Info: Defining free surface
[ Info: Defining ocean simulation
[ Info: Defining ocean simulation
[ Info: Defining closures
[ Info: Defining free surface
[ Info: Defining ocean simulation
[ Info: Defining Atmospheric state
[ Info: Defining Atmospheric state
[ Info: Defining Atmospheric state
[ Info: Defining coupled model
[ Info: Defining coupled model
[ Info: Defining coupled model
[ Info: Defining messenger
[ Info: Defining messenger
[ Info: Defining messenger
[ Info: Defining surface outputs
[ Info: Defining surface outputs
[ Info: Defining surface outputs
[ Info: Saving restart
[ Info: Saving restart
[ Info: Saving restart
ERROR: LoadError: ERROR: LoadError: ERROR: LoadError: MethodError: reducing over an empty collection is not allowed; consider supplying `init` to the reducerMethodError: reducing over an empty collection is not allowed; consider supplying `init` to the reducerMethodError: reducing over an empty collection is not allowed; consider supplying `init` to the reducer
Stacktrace:
  [1] mapreduce_empty(::typeof(identity), op::Function, T::Type)
    @ Base ./reduce.jl:372
  [2] reduce_empty(op::Base.MappingRF{typeof(identity), typeof(max)}, ::Type{Int64})
    @ Base ./reduce.jl:361
  [3] reduce_empty_iter
    @ ./reduce.jl:384 [inlined]
  [4] mapreduce_empty_iter(f::Function, op::Function, itr::Vector{Int64}, ItrEltype::Base.HasEltype)
    @ Base ./reduce.jl:380
  [5] _mapreduce
    @ ./reduce.jl:432 [inlined]
  [6] _mapreduce_dim
    @ ./reducedim.jl:367 [inlined]
  [7] mapreduce
    @ ./reducedim.jl:359 [inlined]
  [8] _maximum
    @ ./reducedim.jl:1017 [inlined]
  [9] _maximum
    @ ./reducedim.jl:1016 [inlined]
 [10] maximum(a::Vector{Int64})
    @ Base ./reducedim.jl:1012
 [11] top-level scope
    @ /g/data/v46/txs156/ocean-ensembles/test/test_restart.jl:241
in expression starting at /g/data/v46/txs156/ocean-ensembles/test/test_restart.jl:241

Stacktrace:
  [1] mapreduce_empty(::typeof(identity), op::Function, T::Type)
    @ Base ./reduce.jl:372
  [2] reduce_empty(op::Base.MappingRF{typeof(identity), typeof(max)}, ::Type{Int64})
    @ Base ./reduce.jl:361
  [3] reduce_empty_iter
    @ ./reduce.jl:384 [inlined]
  [4] mapreduce_empty_iter(f::Function, op::Function, itr::Vector{Int64}, ItrEltype::Base.HasEltype)
    @ Base ./reduce.jl:380
  [5] _mapreduce
    @ ./reduce.jl:432 [inlined]
  [6] _mapreduce_dim
    @ ./reducedim.jl:367 [inlined]
  [7] mapreduce
    @ ./reducedim.jl:359 [inlined]
  [8] _maximum
    @ ./reducedim.jl:1017 [inlined]
  [9] _maximum
    @ ./reducedim.jl:1016 [inlined]
 [10] maximum(a::Vector{Int64})
    @ Base ./reducedim.jl:1012
 [11] top-level scope
    @ /g/data/v46/txs156/ocean-ensembles/test/test_restart.jl:241
in expression starting at /g/data/v46/txs156/ocean-ensembles/test/test_restart.jl:241

Stacktrace:
  [1] mapreduce_empty(::typeof(identity), op::Function, T::Type)
    @ Base ./reduce.jl:372
  [2] reduce_empty(op::Base.MappingRF{typeof(identity), typeof(max)}, ::Type{Int64})
    @ Base ./reduce.jl:361
  [3] reduce_empty_iter
    @ ./reduce.jl:384 [inlined]
  [4] mapreduce_empty_iter(f::Function, op::Function, itr::Vector{Int64}, ItrEltype::Base.HasEltype)
    @ Base ./reduce.jl:380
  [5] _mapreduce
    @ ./reduce.jl:432 [inlined]
  [6] _mapreduce_dim
    @ ./reducedim.jl:367 [inlined]
  [7] mapreduce
    @ ./reducedim.jl:359 [inlined]
  [8] _maximum
    @ ./reducedim.jl:1017 [inlined]
  [9] _maximum
    @ ./reducedim.jl:1016 [inlined]
 [10] maximum(a::Vector{Int64})
    @ Base ./reducedim.jl:1012
 [11] top-level scope
    @ /g/data/v46/txs156/ocean-ensembles/test/test_restart.jl:241
in expression starting at /g/data/v46/txs156/ocean-ensembles/test/test_restart.jl:241
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[8254,1],0]
  Exit code:    1
--------------------------------------------------------------------------
